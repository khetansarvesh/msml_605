## Results

### 1. Training MLE Models
MLE 1-gram perplexity: 691.4702433653597  
MLE 2-gram perplexity: inf  
MLE 3-gram perplexity: inf  
MLE 4-gram perplexity: inf

### 2. Training Add-1 Smoothed Trigram Model
Add-1 smoothed trigram perplexity: 2930.2797642476817

### 3. Training Linear Interpolation Model
Optimal lambdas: (0.4, 0.4, 0.2)  
Linear interpolation perplexity: 213.37374001604283

### 4. Training Stupid Backoff Model
Optimal alpha: 0.9  
Stupid backoff perplexity: 92.10757584975707

### 5. Generating Text

Generated Sentences:
1. yen yesterday 's composite trading under <unk> sierra chemical economic president my car maker jaguar but figures for september fired
2. <unk> neither side savings its board <unk> big brains our big chicken stores in the it cents federal the issue
3. green won a kept engine plant but at least and exchange commission mr that he and <unk> now as campaign
4. <unk> said fk-506 will said separately of <unk> field calif sterling n from being a <unk> company mobil is preparing
5. <unk> teaches government agencies in frankfurt zurich and production restraint by dow jones november n rehabilitation share the big of
